# Bund-ZuwendungsGraph ğŸ•¸ï¸

**Sovereign Knowledge Source** fÃ¼r den Bundes-Formularschrank (Easy-Online). Transformiert unstrukturierte FÃ¶rderrichtlinien in einen maschinenlesbaren Knowledge Graph mit Hybrid Search (Vector + Graph-RAG).

## ğŸš€ Live Demo
**Dashboard:** [https://fÃ¶rderwissensgraph.digitalalchemisten.de](https://fÃ¶rderwissensgraph.digitalalchemisten.de)  
**API-Docs:** [https://fÃ¶rderwissensgraph.digitalalchemisten.de/api/docs](https://fÃ¶rderwissensgraph.digitalalchemisten.de/api/docs)  
**API-Index:** [https://fÃ¶rderwissensgraph.digitalalchemisten.de/api/](https://fÃ¶rderwissensgraph.digitalalchemisten.de/api/)

## âœ¨ Kernfunktionen
- **Automatisierter Crawl:** Monatliche Erfassung neuer Richtlinien aus Easy-Online.
- **Deep Parsing:** Strukturierte Extraktion von Inhalten mit Docling.
- **Hybrid Search:** Kombination aus BM25 (Keyword) und Vektorsuche (Semantik).
- **Graph-RAG:** Kontextuelle Erweiterung von Suchergebnissen durch Beziehungen (z.B. "Ersetzt durch", "Verweist auf").

## ğŸ› ï¸ Architektur
- **Frontend:** D3.js visualisiertes Dashboard (Nginx).
- **Backend:** FastAPI (Python 3.11) fÃ¼r Suche und RAG-Logik.
- **Vector DB:** ChromaDB.
- **Deployment:** Docker Compose mit Nginx Reverse Proxy.

## ğŸ“¦ Deployment & Betrieb

### Voraussetzungen
- Docker & Docker Compose
- API Keys (IONOS Cloud oder Mistral) in `.env`

### Starten
```bash
docker compose up -d --build
```

### Daten-Update (Manuell)
Um neue Dokumente zu crawlen und den Index zu aktualisieren:
```bash
# 1. Neue Dokumente crawlen
docker exec app-backend-1 python src/crawler/easy_online_crawler.py
# 2. Ingest in Vector Store
docker exec app-backend-1 python src/parser/vector_store.py
```

## ğŸ“… Automatisierung
Auf dem Server ist ein monatlicher Update-Zyklus vorgesehen:
1. `easy_online_crawler.py` (Suche nach neuen PDFs)
2. `docling_parser.py` (Extraktion & Graph-Update)
3. `vector_store.py` (Embedding & Index-Update)

---
*Entwickelt als Teil der Forschungsinitiative fÃ¼r transparente Zuwendungsprozesse.*
